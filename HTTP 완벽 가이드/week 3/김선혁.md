# 내용 요약 
## 3부 식별, 인가, 보안 


11. 클라이언트 식별과 쿠키
- 실제로 로봇이나 스파이더는 데이터를 수집하는 과정에서 본의 아니게 웹 사이트에 문제를 일으켰을 때, 해당 사이트의 웹 마스터가 항의 메일을 보낼 수 있도록 From 헤더에 이메일 주소를 기술한다.
- 클라이언트를 인식하고는 싶은데 어떻게 발전해왔는지 설명해줌.
- amazon에서 조차 faturl을 사용한다는게 놀랍다?? 왜 그렇게 했을까? 그냥 레거시 였을까? 

12. 기본 인증
- 작성자도 썼듯이 해당 인증은 매우 위험하고 잘 사용하지 않아서 그냥 이런 것이 있구나~

13. 다이제스트 인증
- 해당 시대에는 조금 센세이션할 수 있겠다 생각함. 그냥 평문으로 보내다가?
- 하지만 이러한 방식보다도 더 현대화된 인증 방식들이 여러 개 있어서 이를 너무 칭찬하고 단점이 너무 평범하게 되어 있어서 아쉬웠음
- 하지만 이 당시에도 사용하는 Base 64 암호화 방식은 현대에서도 사용하고 있어서 조금 더 어떻게 발전해왔는지 궁금했다.

14. 보안 HTTP
- 핸드쉐이킹을 하는 방식 등에 대해서 보다 자세하게 설명해줌.
- 보다 현실에서 많이 사용하는 HTTPS에 대해 원론적으로 왜 나왔는지에 대해 자세하게 설명해줌.

# 질문
- 아마존은 왜 faturl을 사용했을까?
- 이 당시에는 그럼 구글도 다이제스트 인증을 사용했을까? 분명 다른것을 사용했을 것 같다.

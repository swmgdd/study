# 4. 엔터티, 인코딩, 국제화

## 15. 엔터티와 인코딩

-  15.2.3 Content-Length와 지속 커넥션(Persistent Connection)
    - Content-Length는 지속 커넥션을 위해 필수다. 만약 응답이 지속 커넥션을 통해서 온 것이라면, 또 다른 HTTP 응답이 즉시 그 뒤를 이을 것이다. Content-Length 헤더는
      클라이언트에게 메시지 하나가 어디서 끝나고 다음 시작은 어디인지 알려준다. 커넥션이 지속적이기 때문에, 클라이언트가 커넥션이 닫힌 위치를 근거로 메시지의 끝을 인식하는 것은 불가능하다. HTTP
      애플리케이션은 Content-Length 헤더 없이는 어디까지가 엔터티 본문이고 어디부터가 다음 메시지인지 알 수 없을 것이다
- Transfer-Encoding 헤더 필드를 갖고 있는 메시지를 받았다면 반드시 Content-Length 헤더를 무시해야 한다. 왜냐하면 전송 인코딩은 엔터티 본문을 표현하고 전송하는 방식(그리고 아마 전송된
  바이트 크기도)을 바꿀 것이기 때문이다
- 2000년도 초반에 쓰인 책인데 이 당시 쓰인 압축 알고리즘을 지금도 그대로 사용하고 있다.(gzip, deflate...) 이렇게 생각보다 빠르게 변하지 않는 분야도 있다.

## 17. 내용 협상과 트랜스코딩
- 지금은 서버 주도 협상이 대부분인 듯 함.

## 20. 리다이렉션과 부하 균형
- 책의 내용과 같이 스위치 기반의 부하 분산 방식은 더 이상 사용되지 않는다.
  - 또한 해당 스위치는 SDN 기반으로 대체되었다. 
- 현재는 DNS 기반의 부하 분산 방식, 로드밸런서 기반의 부하 분산 방식이 주로 사용된다.


# 질문
- Q. multipart from과 같은 데이터 타입에서는 content lenght가 포함이 안된 경우도 있다고 하는데 이때는 어떻게 지속 연결을 유지할까?

- A. HTTP/1.1에서는 Content-Length 헤더 없이도 데이터를 전송할 수 있는 방법으로 Transfer-Encoding: chunked 방식을 지원합니다. chunked 인코딩을 사용하면 클라이언트가 서버로부터 데이터를 받을 때, 메시지가 끝나는 시점을 알 수 있게 되어 Content-Length 없이도 지속 연결을 유지할 수 있습니다.
이 방법은 특히 multipart/form-data와 같은 데이터를 전송할 때 유용하며, 큰 파일을 전송할 때나 데이터의 길이를 미리 알 수 없을 때 자주 사용됩니다.
Chunked Transfer-Encoding 방식 설명
Transfer-Encoding 설정: 서버는 응답 헤더에 Transfer-Encoding: chunked를 설정합니다. 이렇게 하면 클라이언트는 데이터가 청크 단위로 전달된다는 것을 인식하게 됩니다.
청크 데이터 전송: 서버는 데이터를 크기 단위로 나누어 보냅니다. 각 청크는 청크 크기(16진수로 표시)\r\n청크 데이터\r\n 형식으로 전송됩니다. 마지막 청크는 0\r\n\r\n로 표시하여 데이터가 끝났음을 알립니다.
지속 연결 유지: 클라이언트는 각 청크를 수신할 때마다 연결을 종료하지 않고 데이터를 계속 읽어나가며, 마지막 청크를 받을 때까지 연결을 유지합니다.

- Q. 로드밸런싱(Load Balancing) vs 리버스 프록시(Reverse Proxy)
- A. 로드 밸런싱(Load Balancing)과 리버스 프록시(Reverse Proxy)는 서버로의 트래픽을 분배하고 요청을 관리하는 역할을 하지만, 목적과 사용 방식에서 몇 가지 중요한 차이점이 있습니다.

### 1. 로드 밸런싱 (Load Balancing)

로드 밸런서는 여러 서버에 트래픽을 분산하여 하나의 서버에 과부하가 걸리지 않도록 하는 역할을 합니다. 주로 대규모 애플리케이션에서 트래픽 분산을 위해 사용됩니다.

- **주요 목적**: 트래픽 부하를 여러 서버에 고르게 분산하여 서버가 과부하로 인해 다운되지 않도록 합니다.
- **주된 기능**: 요청을 여러 서버로 분산하며 서버의 상태를 모니터링하여 요청을 안정적인 서버로 전달.
- **사용 사례**: 웹 서버, 애플리케이션 서버 등 여러 서버를 동시에 운영하며 대규모 트래픽을 분산해야 할 때.
- **예시**: 클라우드 서비스의 로드 밸런싱, Nginx, HAProxy 등.

#### 로드 밸런싱 전략 예시
- **라운드 로빈**: 요청을 순서대로 각 서버에 분배.
- **Least Connections**: 현재 연결이 가장 적은 서버로 요청을 분배.
- **IP 해시**: 클라이언트 IP를 기반으로 같은 서버에 요청을 보냄.

### 2. 리버스 프록시 (Reverse Proxy)

리버스 프록시는 클라이언트의 요청을 받아 백엔드 서버에 전달하고, 백엔드 서버의 응답을 클라이언트로 반환하는 중계자 역할을 합니다. 로드 밸런싱과 달리 트래픽 분산 외에도 다양한 기능을 제공합니다.

- **주요 목적**: 보안, 캐싱, SSL 처리, 인증 등 서버 앞단에서의 다양한 기능 제공.
- **주된 기능**: 요청을 받아 적절한 서버로 전달하며 IP를 숨기거나, SSL 종료, 캐싱 등을 통해 응답 성능을 향상.
- **사용 사례**: 보안 강화, 캐싱을 통한 속도 향상, SSL 오프로딩(SSL 처리), 프라이버시 보호.
- **예시**: Nginx, Apache HTTP Server, Cloudflare 등.

### 주요 차이점 요약

| 요소               | 로드 밸런서                                   | 리버스 프록시                                 |
|--------------------|-----------------------------------------------|-----------------------------------------------|
| **목적**           | 트래픽 분산                                   | 서버 앞단에서 다양한 기능 제공                 |
| **기능**           | 부하 분산, 서버 상태 모니터링                | 보안, 캐싱, SSL 처리, 프라이버시 보호          |
| **트래픽 처리 방식**| 다수 서버에 분산하여 서버 부하 관리          | 단일 또는 여러 서버에 요청 중계                |
| **사용 사례**      | 대규모 서버 클러스터                           | 보안 강화, 응답 캐싱, SSL 종료                 |

### 결론

로드 밸런서는 여러 서버 간의 부하를 분산하기 위한 솔루션으로 주로 대규모 시스템에서 사용됩니다. 반면 리버스 프록시는 서버 앞단에서 다양한 기능을 제공하며, 부하 분산 외에도 보안 및 캐싱 역할을 담당합니다.

- Q. 리버스 프록시와 포워드 프록시의 차이점을 알려줘
- A. 포워드 프록시는 클라이언트가 외부 서버에 안전하고 효율적으로 접근할 수 있게 하는 데 주로 사용되고, 리버스 프록시는 외부에서 내부 서버로의 요청을 중개하며 서버의 부하를 줄이고 보안을 강화하는 데 주로 사용됩니다.